%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% CL provided template
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt,a4paper,oneside,openright]{report}

% makes subsubsections appear in the toc
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

% turns references into hyperlinks
\usepackage[pdfborder={0 0 0}]{hyperref}
\newcommand{\URL}[1]{\href{https://#1}{\textcolor{cyan}{\texttt{#1}}}}

\usepackage{tablefootnote}

% adjusts page layout
\usepackage[margin=25mm]{geometry}

% allows inclusion of PDF, PNG and JPG images
\usepackage{graphicx}
\graphicspath{ {figs/} }

\usepackage{verbatim}

% try to avoid widows and orphans
\raggedbottom
\sloppy
\clubpenalty1000%
\widowpenalty1000%

% adjust line spacing to make more readable
\renewcommand{\baselinestretch}{1.1}

% add colour to TODOs
\usepackage{xcolor}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Maths
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{amsmath}        % American Mathematical Society
\usepackage{amssymb}        % Maths symbols
\usepackage{amsthm}         % Theorems
\usepackage{mathpartir}    % Proofs and inference rules

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Floats
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{float}
\usepackage[labelfont=bf,margin=10pt]{caption}
\usepackage{subcaption}
\newcommand{\mycaption}[2]{\caption[#1]{#1 #2}}

\floatstyle{plain}
\restylefloat{figure}
\restylefloat{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
% Figures
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{tikz}
\usepackage{pgfplots}

\newcommand{\graphWidth}{15cm}

% Shamelessly stolen to draw VBox diagrams
\usepackage{threads}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Tables
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{array}
% control width and vertically align text in table cells
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}p{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}p{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}p{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Listings
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{fancyvrb}

\floatstyle{boxed}
%\floatstyle{ruled}
\newfloat{Listing}{tbp}{lol}[chapter]

\DefineVerbatimEnvironment{JavaCode}{Verbatim}
{fontfamily=courier,baselinestretch=1,gobble=4}

\DefineVerbatimEnvironment{GoCode}{Verbatim}
{fontfamily=courier,baselinestretch=1,gobble=4}

\usepackage{listings}
\usepackage{color}
\usepackage{mathtools}

\definecolor{dkgreen}{rgb}{0,0.4,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{
  language=Java,
  aboveskip=0mm,
  belowskip=0mm,
  showstringspaces=false,
  %columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=left,
  keywordstyle=\bfseries,
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=4
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Semantic and convenience macros
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\TOBEDONE}{{\LARGE To be done...}}
\newcommand{\todo}[1]{\textcolor{red}{TODO: #1}}
\newcommand{\note}[1]{\textcolor{blue}{NOTE: #1}}

\newcommand{\javaLiteral}[1]{\texttt{#1}}
\newcommand{\javaCode}[1]{\texttt{#1}}
\newcommand{\javaClass}[1]{\texttt{#1}}
\newcommand{\javaSlot}[1]{\texttt{#1}}
\newcommand{\javaVariable}[1]{\texttt{#1}}
\newcommand{\javaKeyword}[1]{\texttt{#1}}
\newcommand{\javaMethod}[1]{\texttt{#1}}
\newcommand{\javaException}[1]{\texttt{#1}}
\newcommand{\javaAnnotation}[1]{\texttt{#1}}

\newcommand{\goCode}[1]{\texttt{#1}}
\newcommand{\goType}[1]{\texttt{#1}}
\newcommand{\goValue}[1]{\texttt{#1}}
\newcommand{\goVariable}[1]{\texttt{#1}}
\newcommand{\goKeyword}[1]{\texttt{#1}}
\newcommand{\goFunc}[1]{\texttt{#1}}

\newcommand{\keyTerm}[1]{\textbf{#1}}

\newcommand{\codeemph}[1]{\textbf{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Info about dissertation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\disstitle}{Software Transactional Memory implementation
  and benchmarking in Go}
\newcommand{\college}{Churchill College}
\newcommand{\studentname}{Rui Cachopo}
\newcommand{\candidatenumber}{2399F} %checked Moodle on 25/04/2020
\newcommand{\studentemail}{rmc82@cam.ac.uk}
\newcommand{\wordcount}{11970}
\newcommand{\loc}{5234}
\newcommand{\originator}{\candidatenumber}
\newcommand{\supervisor}{Tim Harris}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Start of document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\bibliographystyle{apalike}

\pagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Cover page
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\rightline{\LARGE \textbf{\studentname}}

\vspace*{60mm}
\begin{center}
  \Huge
  \textbf{\disstitle} \\[5mm]
  Computer Science Tripos -- Part II \\[5mm]
  \college \\[5mm]
  \today
\end{center}

\newpage

\section*{Declaration}

I, \studentname\ of \college, being a candidate for Part II of the
Computer Science Tripos, hereby declare that this dissertation and the
work described in it are my own work, unaided except as may be
specified below, and that the dissertation does not contain material
that has already been used to any substantial extent for a comparable
purpose.

I, \studentname\ of \college, am content for my dissertation to be
made available to the students and staff of the University.

\bigskip \leftline{Signed: }

\medskip \leftline{Date: \today}

\newpage

\section*{Acknowledgements}

The comparatively small margins of this page cannot possibly contain
all acknowledgements due in this dissertation. I give instead a much
paler summary, and hope my gratefulness can be shown in some other
way.

\medskip

First of all, I would like to thank Tim Harris for supervising this
project. My work would have been much less interesting, and this
dissertation much less coherent, without his guidance and support.

\medskip

I would also like to thank John Fawcett and Matthew Ireland, for
making sure I stayed mostly on track for the last three years.

\medskip

Many thanks are due to my parents, for leading me most of the way to
the finish line. To my mother, for all her support and willingness to
help. To my father, for letting me stand on his shoulders when
producing this work.

\medskip

I would like to thank AN for always being present and willing to hear
about my work, and RM for coercing me to step away from it
occasionally. Finally, I would like to thank them both for helping me
keep a vestige of sanity.


\chapter*{\vspace{-1.2in} Proforma \vspace{-0.3in}}

\thispagestyle{empty}

\vspace{-0.2in}

\begin{table}[h]
  \begin{tabular}{L{0.3\linewidth} L{0.7\linewidth}}
    \textbf{Candidate number:} & \candidatenumber                      \\
    \textbf{Project Title:}           & \disstitle \\
    \textbf{Examination:}        & Computer Science Tripos -- Part II, 2020  \\
    \textbf{Word Count:}         & \wordcount\tablefootnote{Calculated
                                   using TeXcount: \URL{app.uio.no/ifi/texcount}} \\
    \textbf{Lines of code:} & \loc\tablefootnote{Calculated using
                              Github's ``Contributors'' feature.} \\
    \textbf{Project Originator:} & \originator \\
    \textbf{Supervisor:} & \supervisor \\
  \end{tabular}
\end{table}

\vspace{-0.4in}

\section*{Original aims of the project}

The core goals of the project were to implement a Software
Transactional Memory and to make a meaningful evaluation of the system
produced. This evaluation involves both quantitative benchmark results
and qualitative results related to the usability of the system. The
technical deliverables are implementations of the STM and the
benchmark produced --- as there is no existing realistic benchmark in
the language chosen for this project.

\vspace{-0.1in}

\section*{Work completed}

All the success criteria of the project have been met. I implemented
the Go Versioned Software Transactional Memory and demonstrated its
correctness and performance by producing an implementation of the
STMBench7 benchmark and accompanying tests. Due to the difficulties
described in the section below I had much less time than I had hoped
to work on extension tasks.

The completion of this work required substantial research into
Transactional Memory and Go's concurrency primitives and memory
model. Implementation of an application as large as the STMBench7
benchmark also required knowledge and use of software engineering
patterns and good practices.

\vspace{-0.1in}

\section*{Special difficulties}

In November 2019 I had a climbing accident that resulted in a
dislocated elbow. This halted project work, and in fact all academic
work, for a few weeks until I was able to use a keyboard again.

Starting in March 2020, the COVID-19 pandemic forced me, and indeed
the vast majority of students, to work from home for the rest of the
academic year. This meant that the last month of work on the project
and this dissertation were completed in an environment much less
productive than expected.

\newpage

\pagestyle{plain} \pagenumbering{roman}

\tableofcontents

\newpage

\begingroup \let\clearpage\relax \listoffigures{}
\listof{Listing}{List of Listings} \endgroup


\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% #Content
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagestyle{headings}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Intro
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}

\pagenumbering{arabic}

This dissertation describes the implementation and benchmarking of a
Software Transactional Memory (STM) in Go, a programming language that
emerged just as research on STMs dwindled. In this chapter I aim to
give a brief historical background of STMs and explain the choices I
made when proposing the project. In particular, I explain the choice
of STM algorithm, programming language and benchmark to use.

\section{Motivation and previous work}
\label{sec:motivation}

To have some context on the motivations behind STMs, it makes most
sense to first remember the historical trends in processor
design. From there, we can see how modern hardware limitations caused
a revolution in software and the problems that this caused to
programmers. Finally, we can see how STM tackles these problems.

\subsection{The problem}
\label{sec:problem}

In the last few decades, and especially in the period of 1986--2003,
single-core processor performance grew exponentially at such a rate
that hardware became obsolete within one or two years. This was mostly
thanks to two ``laws'' of processor design: Moore's
law~\cite{MooreLaw} and Dennard scaling~\cite{DennardScaling}. Moore's
law is the observation that, due to the production of smaller
transistors, the number of transistors in a processor doubles every
two years. Although the prediction in the 1965 paper was a doubling in
transistor count every year, this was revised in 1975 to a doubling
every two years. Dennard scaling states that as transistors get
smaller and consume less power, their power density stays constant, so
the power consumption of the whole processor remains constant.

The combination of these laws impacts processor performance in three
main ways:

\begin{itemize}
\item Smaller transistors can switch faster, meaning that the clock
  frequency of the processor can be increased.
  
\item The higher transistor budget allows for more complex hardware
  design. One way this was exploited was the use of pipelining, which
  reduces the critical path inside processor and allows the clock
  frequency of the processor to increase.
  
\item More complex hardware design was also used to build
  out-of-order, superscalar processors. These processors could exploit
  Instruction Level Parallelism (ILP)~\cite[Chapter~3]{CompArchBook}
  latent in most programs.
\end{itemize}
This processor performance ``free lunch''~\cite{FreeLunchIsOver} ended
in the early 2000s, when Dennard scaling ceased to hold and the
low-hanging fruit of processor design had been harvested:

\begin{itemize}
\item In post-Dennard scaling, power consumption becomes a limiting
  factor in the complexity of a single core and on the clock frequency
  of the processor.
  
\item The performance penalties caused by processor stalls, such as
  cache misses and mispredicted branches, increases with the length of
  the processor pipeline. This means deeper pipelines yield
  diminishing returns.
  
\item The amount of ILP latent in most programs is limited. This means
  that increasingly complex superscalar hardware will also yield
  diminishing returns.
\end{itemize}
As the limits of single-core performance and latent ILP were reached,
processor designers shifted their focus to multicore processors, which
are capable of exploiting Thread Level Parallelism
(TLP)~\cite[Chapter~5]{CompArchBook}. As opposed to ILP, which can be
automatically exploited by the processor in most applications, TLP
usually requires the program to be written using multiple
threads. This means that the burden is now on programmers to write
concurrent applications if they want to reap the benefits of
increasing processor performance. Enter the software revolution
towards concurrent programming.

\subsection{Possible solutions}
\label{sec:possible-solutions}

\paragraph{Locking.} The model most commonly used in concurrent
programs consists of multiple threads, which communicate through
access to shared memory. Low level primitives such as locks are used
to provide condition synchronisation and mutual exclusion when
accessing shared resources. This model is sufficient for simple
programs, but it does not scale to large applications. Problems such
as deadlock and priority inversion are hard to detect and debug in
large programs. The lack of a semantic link between a mutex lock and
the resource it protects leads to what Herlihy and Shavit call
``synchronisation by convention''~\cite[Chapter
18]{ArtMultiprocessorProgramming}.

\begin{Listing}[hbtp]
\begin{lstlisting}
/* When a locked buffer is visible to the I/O layer BH_Launder
 * is set. This means before unlocking we must clear BH_Launder,
 * mb() on alpha and then clear BH_Lock, so no reader can see
 * BH_Launder set on an unlocked buffer and then risk to
 * deadlock.
 * /
\end{lstlisting}

  \mycaption{Synchronisation by convention.}{This Linux kernel comment
    demonstrates how real-world concurrent systems rapidly become
    complex.}
  \label{lst:syncConv}
\end{Listing}

\paragraph{Monitors and condition variables.} Several approaches have
been suggested as solutions to the problems present when using locks
and shared memory. The most basic of these is the use of slightly
higher level primitives, such as monitors and condition
variables. Java is a good example of this: the JVM associates one
monitor and one condition variable with each object. A
\javaKeyword{synchronized} code block runs inside a monitor, which can
be used to provide mutual exclusion. The condition variables can be
used for condition synchronisation using the \javaMethod{wait},
\javaMethod{notify} and \javaMethod{notifyAll} methods.

\paragraph{Message passing.} Moving away from threads and shared
memory, other concurrency models have been created. The most
widespread involve message passing between strongly isolated processes
--- so called because, unlike threads, they do not share
memory. Hoare's Communicating Sequential Processes~\cite{CSP} and
Milner's Calculus of Communicating Systems~\cite{CCS} are two formal
models that use this idea. These models are mostly employed by
functional programming languages such as Erlang, which allow no shared
memory and in which all data is immutable. Concurrent programs in
these languages can be simpler to write and debug, but often do not
perform as well as programs written in more ``traditional'' languages
such as Java and C\texttt{++}.

\paragraph{Transactional memory.} Yet another approach, and the focus
of this dissertation, is Transactional Memory (TM)~\cite{TMBook}. When
using transactional memory, a programmer organises their code into
transactions, similar to the transactions in the transactional model
of databases. It is then up to the underlying TM implementation to
provide atomicity and isolation of the transactions executed. That is,
the memory operations of each transaction executed appear to occur
atomically, and no transaction can see the results of a partial
execution of any other transaction.

\subsection{Transactional memory}
\label{sec:transactional-memory}

Transactional memories provide a very simple interface to programmers:
to write a correct concurrent program, place all parallel code that
accesses shared data inside transactions, and let the underlying TM
ensure the program is correctly synchronised. Transactional memories
also provide composability, meaning it is simple to compose existing
transactions to achieve more complex behaviour. As an example,
consider that we want to dequeue an element from a concurrent queue
$Q_1$ and enqueue it in concurrent queue $Q_2$, but without any other
thread observing that the element is in neither or both queues at the
same time. Attempting to solve this problem with locks would be fairly
complex, involving either additional locks or exposing the internal
locking logic of the concurrent queues. In a TM model, however, the
solution is trivial: simply execute both operations in the same
transaction. This is discussed in more depth in
Section~\ref{sec:prep:techn-requ}.

Transactional memories can be implemented in hardware or
software. Hardware Transactional Memories (HTM)~\cite{HTM} are usually
implemented on top of the cache coherence protocol of a processor, and
are offered as an Instruction Set Architecture (ISA)
extension. Because they operate at such a low level, HTMs are often
very efficient, but the size of transactions is limited by the size of
cache available and the implementation cost is extremely
high. Software Transactional Memories (STM)~\cite{STM} are much more
flexible, but implementing them efficiently can be a
challenge. Efficiency concerns with regards to STMs are so great that
they have been called a ``research toy''~\cite{Toy}.

\section{Golang}
\label{sec:intro:golang}

In this project I aim to implement an STM and evaluate its
performance. I have chosen to do this in Go\footnote{\URL{golang.org}}
because it is a language that emerged after the wave of research on
STMs in the early 2000s, and so there is no exploration of how the
language's features can be exploited to increase the applicability of
STM approaches. Additionally, Go is designed with concurrency as a
primary focus. In fact, one of the primary uses of Go has been to
build server applications, and there is a growing environment of tools
and libraries to support this. Examples are Docker and Kubernetes
implementations, the etcd key-value store
system\footnote{\URL{etcd.io}}, the Elasticsearch-Logstash-Kibana
stack for logging\footnote{\URL{elastic.co/what-is/elk-stack}} and
Prometheus for metric tracking\footnote{\URL{prometheus.io}}. One of
my goals when choosing to use Go for this project was to eventually
contribute to this environment, and make it easy for software
engineers to build server applications using STM.

\section{The STM chosen}
\label{sec:stm-chosen}

Although there has been substantial research on the topic of
transactional memory, and many STMs have been implemented, there are
few applications that actually use them. From a software engineering
perspective, there are many possible reasons for this, such as
adoption costs and little to no support of commonly used libraries. As
one of my goals in choosing my project was to one day develop an STM
that could be adopted in industry, it made sense to base my project on
an existing STM with a real-world application. Such an STM is the Java
Versioned Software Transactional Memory
(JVSTM)\footnote{\URL{web.ist.utl.pt/joao.cachopo/jvstm/}}, which has
been used in the FenixEDU
project~\cite{carvalho2008versioned}. Because my STM uses the same
version box--based algorithm~\cite{VBox} but is implemented in Go
instead of Java, I have decided to name it Go Versioned Software
Transactional Memory (GVSTM).

\section{Evaluation and benchmarking}
\label{sec:eval-benchm}

Performance is a crucial factor in the evaluation of STMs. Although it
has been shown that STMs can largely outperform sequential code in
multicore computers~\cite{MoreThanToy}, it falls to each STM
implementation to show that it is sufficiently efficient to be
adopted. With that goal in mind, it is important for the success of
this project to demonstrate how the STM implemented performs when
compared to alternatives, even if it does not outperform them.

With that in mind, I have chosen to include in the evaluation of my
STM the results of the STMBench7 benchmark, which can be regarded as a
stress test of STMs~\cite{STMBench7}. STMBench7 aims to be a realistic
benchmark, meaning that instead of performing a long series of simple
transactions, such as reading and writing a handful of variables, it
performs elaborate operations on complex data structures. A
description of the benchmark and its data structures and operations
can be found in Section~\ref{sec:impl:stmbench7}.

As of the start of this project, there is no Go implementation of
STMBench7. This means that a considerable part of the work to be
completed, both in terms of lines of code written and time investment,
will consist of adapting the existing Java version to be implemented
in Go. Because of the complexity and size of the benchmark, my
proposal is to implement a subset of the original 45
operations. Completing the implementation of the benchmark is an
extension goal of the project.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Preparation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Preparation}

I begin this chapter with an overview of my relevant experience and
work completed before the start of the project
(Section~\ref{sec:prep:starting-point}). I then describe the
requirements of an STM, from both a functional perspective and one of
producing a system that can be adopted in a software engineering
environment (Section~\ref{sec:requ-analys}). I also give an overview
of the research conducted to become familiar with the features of Go
that had a significant impact on the design decisions of this project
(Section~\ref{sec:prep:research}. I conclude the chapter by describing
my engineering methodology, as well as details of the systems used
(Section~\ref{sec:engin-meth}).

\section{Starting point}
\label{sec:prep:starting-point}

Here I summarise knowledge relevant to the project that I acquired
outside of the Computer Science Tripos. Within the Tripos, the courses
most relevant to this project are Part IB Concurrent and Distributed
Systems, which covers the basic shared memory synchronisation
mechanisms, and the Multicore Semantics and Programming Unit of
Assessment, which covers memory models and more advanced
synchronisation mechanisms such as Transactional Memory.

\paragraph{Experience with Go programming.} During my internship after
Part IB of the Tripos I learned Go and used it to build server
applications using the microservice architecture. My experience with
Go here was mostly using both internal and external libraries, and did
not involve using Go's concurrency primitives explicitly.

\paragraph{Knowledge of the STM algorithm.} I was first introduced to
the concept of Transactional Memory in the last concurrency lecture of
the Part IB Concurrent and Distributed Systems course, which touched
on a few topics. I was intrigued, so I spent some time reading about
transactional memory, and about the JVSTM in particular. This gave me
a good general understanding of the algorithm used, but I did not look
into implementation specifics.

\paragraph{Prototype built for project proposal.} Before proposing
this project to my supervisor I created a prototype of the GVSTM, to
verify that the task I was setting out to do was feasible within the
context of a Part II project. This prototype was just over one hundred
lines of code and lacked essential features such as garbage collection
of old versions --- by far the most complex part of the STM
algorithm. As discussed in Section~\ref{sec:impl:garbage-collection},
this meant that a program using the GVSTM would quickly run out of
memory.

\paragraph{Access to JVSTM and STMBench7 codebases.} The JVSTM
codebase is freely available in its GitHub
repository\footnote{\URL{github.com/inesc-id-esw/jvstm}}. The
STMBench7 benchmark is sadly no longer available at its
homepage\footnote{\URL{dcl.epfl.ch/transactions/wiki/doku.php?id=stmbench7}},
but it is available in the JVSTM benchmarks
repository\footnote{\URL{github.com/inesc-id-esw/jvstm-benchmarks/tree/master/stmbench7}}.

\section{Requirements analysis}
\label{sec:requ-analys}

The requirements of a transactional memory can be divided into
functional and quality requirements. Functional requirements must be
met for a TM to be classified as such and to provide correct
synchronisation. Quality requirements should be met for a TM to be a
viable alternative to other synchronisation mechanisms and to be
adopted by software engineers. In this project I will make sure that
the GVSTM meets the functional requirements. The quality requirements
will be use as an aspect of evaluation of the GVSTM, but are not part
of the success criteria of the project.

\subsection{Functional requirements}
\label{sec:prep:techn-requ}

\paragraph{ACID properties.} Any transactional memory must provide
Atomicity, Consistency and Isolation according to the ACID properties
of the database transactional model. Atomicity guarantees that each
transaction either commits or aborts fully --- no transaction may
conclude with only some of its memory operations successfully
executed. Consistency guarantees that the result of executing a
transaction on a consistent view of the program will result in a
consistent view of the program. Isolation can be provided to varying
degrees. In the context of the ACID properties, isolation guarantees
that no committed transaction may have seen the results of a partial
execution of another transaction. Durability concerns the resilience
of committed transactions to system failures, often by using
non-volatile storage. Because TM operates only in main memory,
durability is not a concern today, though this may change in the
future.

\paragraph{Opacity.} In practice, modern transactional memories are
expected to make stronger guarantees than those provided by the ACID
properties. Opacity~\cite{Opacity} is widely regarded as the
correctness property to be achieved by TMs, and is stronger than
properties imported from the area of database concurrency control such
as serialisability and strict
serialisability~\cite{Serialisability}. In summary, opacity
strengthens the isolation condition so that no transaction, including
aborted and in-flight transactions, can access inconsistent
states. The GVSTM provides opacity by only allowing each transaction
to access the state consistent with its read timestamp --- see
Section~\ref{sec:impl:vers-data-struct}.

\paragraph{Serialisation order.} Although not sufficient, the property
of strict serialisability gives rise to a useful construct: the
serialisation order of transactions. This is the sequential order in
which transactions appear to occur. It is common to say, for example,
that transaction $A$ is serialised after transaction $B$.

\paragraph{Reading and writing transactional variables.} In the
general case, a transactional memory could provide the properties
above to many kinds of operations, such as I/O and, in the case of Go,
channel communication. Providing such a general solution from scratch,
in addition to implementing a benchmark to meaningfully evaluate it,
would be far beyond the scope of an undergraduate project. As such, I
decided to focus on implementing an STM that provides the properties
above only to reads and writes of transactional
variables. Section~\ref{sec:impl:extensions} briefly discusses how the
GVSTM could be extended to handle arbitrary operations
transactionally. There is, however, a case to be made against using
different concurrency models such as TM and channel communication in
the same program.

\paragraph{Composability.} One of the most appealing features of STM
when compared to other synchronisation mechanisms is the ease of
composition of transactions. As shown in
Listing~\ref{lst:composability}, given transactional methods to add
and remove an element from a queue, a transactional method to move an
element from one queue to another is trivial, as is the creation of an
atomic version of said method.

\begin{Listing}[hbtp]
\begin{lstlisting}
func transactionalEnqueue(queue Q, element E) {...}

func transactionalDequeue(queue Q) E {...}

func transactionalMove(queueOne, queueTwo Q) {
    element := transactionalDequeue(queueOne)
    transactionalEnqueue(queueTwo, element)
}

func atomicMove(queueOne, queueTwo Q) {
    Atomic(func() {
        transactionalMove(queueOne, queueTwo)
    })
}
\end{lstlisting}

  \mycaption{Composability.}{The pseudocode presented here uses syntax
    similar to that of Go, but does not obey the syntax of
    transactional methods defined later in this dissertation.}
  \label{lst:composability}
\end{Listing}


\subsection{Quality requirements}
\label{sec:prep:usab-requ}

\paragraph{Performance.} One of the principal concerns of STM
designers is performance. Depending on the algorithm used, it may be
necessary to keep large read- and write-sets or perform complex
conflict detection operations, which may introduce significant
overheads (see Section~\ref{sec:impl:diff-meth-deal}). For software
engineers to choose to adopt an STM it must demonstrate that its
performance is at least comparable to that of other solutions, in
addition to simplifying the programming model used. Performance may
have different meanings in different applications:
\begin{itemize}
\item Some applications may require an upper bound on the latency of
  any operation.
\item Some applications may prefer to minimise the latency of read
  operations at the cost of increasing the latency of write
  operations.
\item Some applications may try to ensure maximal throughput, while
  giving no guarantees on the performance of individual operations.
\end{itemize}
Of the three examples here, the first is likely to occur in real-time
applications, such as high-frequency trading or security-critical
applications. Transactional memory is unlikely to be a sensible
solution in these cases. The latter two examples are more likely to
occur in server applications, in which STM is much more promising. The
GVSTM in particular is heavily read-optimised, and guarantees
low-latency read-only operations regardless of the presence of
write-operations.

\paragraph{Usability.} As discussed in Section~\ref{sec:problem},
synchronisation using locks is difficult for a number of
reasons. Programming using an STM should not only make it easier to
write correct concurrent programs, but also be easy and intuitive to
use and shorten iteration times for software engineers. Short of
surveying a large number of software engineers with experience
programming using multiple concurrency models, an evaluation of
usability will be somewhat subjective.

\section{Research: using Go to implement an STM}
\label{sec:prep:research}

Part of the research necessary to complete this project was to become
familiar with features of Go that are essential to the implementation
of an STM and of a benchmark that is itself a significant software
project. In this section I summarise these features, focusing on where
they differ from Java's, the language originally used to implement the
JVSTM and STMBench7. I will include small code examples, and I
recommend that those unfamiliar with Go read this section. More detail
on these topics can be found in Go's
specification\footnote{\URL{golang.org/ref/spec}} and memory
model.\footnote{\URL{golang.org/ref/mem}}

\subsection{Polymorphism}
\label{sec:prep:polymorphism}

Go, at the time of writing (version 1.14), does not offer generic
programming, but supports polymorphism in the form of interface
types. Interface types declare a set of methods --- an interface. Any
type that implements all methods of an interface is said to implement
the corresponding interface type. See Listing~\ref{lst:interfaceTypes}
for an example.

A particularly interesting interface type is the empty
interface. Because its method set is empty, all types implement
it. This makes it useful for implementing libraries that must support
operations on arbitrary types, because it allows the creation of a
single method that supports all types instead of having distinct
methods for each type. Compared to generic programming this has the
disadvantage of requiring users to explicitly cast values to the
particular types they expect said values to have. This is cumbersome
but, sadly, the best solution available in Go at the moment.

\begin{Listing}[hbtp]
\begin{lstlisting}
type bird interface {
    eat()
}

type duck interface {
    walk()
    quack() string
}

type mallard struct {...}

func (m mallard) eat() {...}

func (m mallard) walk() {...}

func (m mallard) quack() string {...}

type barnacle struct {...}

func (b barnacle) eat() {...}

func (b barnacle) honk() string {...}
\end{lstlisting}

  \mycaption{Interface types.}{Type \goType{mallard} implements
    \goType{duck} and \goType{bird}. Type \goType{barnacle} implements
    \goType{bird} but not \goType{duck}. Both concrete types implement
    the empty interface \goType{interface\string{\string}}.}
  \label{lst:interfaceTypes}
\end{Listing}


\subsection{Object semantics}
\label{sec:prep:oop}

Function arguments in Go are passed by value, including method
receivers. This means that in the example in
Listing~\ref{lst:interfaceTypes}, each time a method of the
\goType{mallard} type is called, a copy of the struct is made. If the
method changes some fields of the struct the value held by the parent
is unchanged. In large software projects, and indeed ones ported from
an object oriented language, it is useful to have the concept of an
object, in which updates on an object made by one part of the program
can be seen by other parts.

To get such semantics in Go, it suffices to change the receiver type
of methods to a pointer type. This means that instead of type
\goType{mallard} implementing interface type \goType{duck}, pointer
type \goType{*mallard} implements interface type \goType{duck}. This
is, in practice, more common in Go, and can be seen for example with
the implementations of the \goType{sync.Locker} interface type, which
is the interface implemented by locks.

\subsection{Errors and panics}
\label{sec:prep:panics-errors}

For the sake of brevity, I will assume the reader is comfortable with
Java's exceptions, and with the distinction between checked and
unchecked exceptions. Because exceptions can alter the flow of
execution, they raise some questions with STM implementations:

\begin{itemize}
\item If a transaction causes an exception, should it commit or abort?
\item If the former, will the transaction maintain the consistency
  property mentioned in Section~\ref{sec:prep:techn-requ}?
\item If the latter, will the condition that caused the exception
  still hold and be reproducible?
\item Should a transaction be able to raise an exception due to seeing
  an inconsistent state --- if the STM does not provide opacity?
\end{itemize}

Go's analogous to checked exceptions are values of type \goType{error}
--- ordinary values that can be manipulated, passed as arguments and
returned by functions.  Due to Go's support of multiple return values,
functions that may generate an error \goType{error} typically return
it as the last return value. It is expected that the caller of a
function that returns an \goType{error} will check that error is
\goValue{nil}, similarly to the handling of exceptions in Java.

Go's analogous to unchecked exceptions are calls of the \goFunc{panic}
function. A call of \goFunc{panic} shifts execution up the call stack
until the program exits, reporting the error condition, or the
\goFunc{recover} function is used to stop the panicking
sequence. Calls of \goFunc{panic} should only be used when unexpected
errors occur --- it is unidiomatic to use calls of \goFunc{panic} for
control flow. Listing~\ref{lst:errorPanic} shows an example of the use
of \goType{error} and \goFunc{panic}.

\begin{Listing}[hbtp]
\begin{lstlisting}
func main() {
    _, err := os.Create("/file/path")
    if err != nil {
        panic(err)
    }
    // Calculate results and write to file
}
\end{lstlisting}

  \mycaption{\goType{error} and \goFunc{panic}.}{In this case failure
    to create the file is sufficiently unexpected that we want the
    program to terminate.}
  \label{lst:errorPanic}
\end{Listing}

\subsection{Goroutines}
\label{sec:prep:goroutines}

Go supports goroutines, which are essentially light-weight
threads. Goroutines are inspired by coroutines, but are subtly
different, particularly because they imply concurrency and coroutines
do not. I assume that the reader is familiar with threads, so instead
of explaining goroutines from scratch I will describe the main aspects
in which they differ from threads and that are relevant to this
project:

\begin{itemize}
\item The only memory associated with a goroutine is its dynamically
  sized call stack. This is a lot cheaper than threads in Java, which
  have a large, fixed-size stack and associated objects holding state
  such as Thread ID and thread-local storage --- see
  Section~\ref{sec:prep:thread-locals}.
\item Goroutines are anonymous. Go does not have a representation of a
  running goroutine analogous to Java's \javaClass{Thread} objects,
  and it is not possible in Go to stop or resume one goroutine from
  another.
\item Goroutines are multiplexed onto OS threads by the Go
  runtime. Because goroutines are so cheap to create and run, it is
  often practical to have very large numbers of goroutines running
  concurrently, even if the number of available processors and OS
  threads is small.
\end{itemize}

\subsection{Thread-local storage}
\label{sec:prep:thread-locals}

Java supports thread-local storage. As the name suggests, this is
storage that holds variables that differ between threads. Because in
an STM each transaction is running in its own thread, thread-local
storage can be used to keep any bookkeeping necessary by the
transaction. As an example, the JVSTM uses Java's
\javaClass{ThreadLocal}'s to keep the transaction objects necessary to
validate and commit read-write transactions --- see
Section~\ref{sec:algorithm-overview}.

As mentioned in Section~\ref{sec:prep:goroutines}, goroutines are much
more light-weight than Java's threads, and do not support thread-local
storage. When I started this project, I spent some time researching
ways to implement thread-locals. Thread-locals can be implemented by
using a thread ID, or in this case goroutine ID, as an index in a map
of ID to the corresponding thread-local state. However, as described
in Section~\ref{sec:prep:goroutines}, goroutines are anonymous, and
there is not an appropriate way of determining the ID of a goroutine
--- the only ways are inefficient, ``hacky'' and generally frowned
upon\footnotemark.  \footnotetext{A brief, entertaining overview of
  this can be found at
  \URL{blog.sgmansfield.com/2015/12/goroutine-ids}}

\subsection{Memory model}
\label{sec:prep:memory-model}

The memory model of a language defines which values can be seen when
multiple threads access shared memory concurrently. As work by Peter
Sewell and others has illustrated, defining memory models is difficult
in the presence of optimising compilers and complex hardware. The
``Multicore Semantics and Programming'' unit of
assessment\footnote{\URL{cl.cam.ac.uk/teaching/1920/Multicore}} is a
good introduction to this topic.

Go's memory model, similarly to Java's, defines a happens-before
relationship between synchronisation operations. In Go, the
synchronisation operations are fewer: they mostly concern lock
acquisition, the creation of goroutines and channel communication. The
memory model lacks guarantees on shared memory accesses analogous to
the guarantees provided by Java's \javaCode{volatile} and
\javaCode{final} variables, on which the JVSTM relies to provide
synchronisation of its lock-free components. That being said, the
documentation of the \goCode{sync/atomic} package seems to assume that
its operations have similar semantics to those of Java's
\javaCode{volatile} variables.

\section{Engineering methodology}
\label{sec:engin-meth}

\paragraph{Version control and backup policy.} I kept the source code
of my project in a Git repository publicly available on my GitHub
profile. The \LaTeX\ and accompanying source files of this
dissertation are in a private Git repository. In addition to the
repositories hosted on GitHub and the clones on my local machine, I
kept a backup of the contents of my local machine in an external disk,
which I updated weekly.

\paragraph{Test-driven development.} One of the most important lessons
learnt during my internships is the value of test-driven development
in software projects. However, because this project involved designing
an interface that was subject to change, it made more sense to
complete the implementation of the STM before writing tests for
it. During the implementation of STMBench7, the data structure
invariant tests were written as soon as possible to detect bugs early.

\paragraph{Tools.} I used the GoLand IDE to write, test and benchmark
my code, and the \texttt{gofmt}
tool\footnote{\URL{golang.org/cmd/gofmt}} to format it according to
common style guidelines.

\paragraph{Versions and licenses.} I wrote my project using Go version
1.12. My implementation of the GVSTM is based on the description of
the JVSTM algorithm~\cite{cachopo2007phd}. My implementation of
STMBench7 is based on the Java source code of the benchmark, version
1.2, licensed under
BSD-3-Clause\footnote{\URL{opensource.org/licenses/BSD-3-Clause}}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Implementation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Implementation}

I begin this chapter with an overview of some concepts that are
central to the understanding of STMs regardless of the language and
algorithm used (Section~\ref{sec:stm-concepts}). I then describe the
steps taken to design a general approach to STM implementation in Go
(Section~\ref{sec:design-decisions}), and how this is based on the
preliminary research summarised in
Section~\ref{sec:prep:research}. The main implementation tasks of the
project, the GVSTM and STMBench7, are discussed in
sections~\ref{sec:impl:gvstm} and~\ref{sec:impl:stmbench7},
respectively. At the end of the chapter, I include an overview of the
repository for the interested reader to use as reference
(Section~\ref{sec:impl:repository-overview}).

\section{STM concepts}
\label{sec:stm-concepts}

The concepts discussed here are applicable to STMs in general and will
be used in later sections when describing the implementation of the
GVSTM.

\subsection{Conflicts}
\label{sec:impl:conflicts}

Two concurrent transactions are said to conflict semantically if the
result of their execution is not the same as the result of some
sequential execution of the two transactions. This implies that the
operations of one of the transactions affect the outcome of the other.

Because in this project I focus only on operations on transactional
variables, this can occur only if one transaction writes to a
transactional variable from which the other transaction reads --- a
Read-After-Write conflict on a transactional variable. This, in fact,
is an overly conservative approximation to conflict detection --- it
detects physical conflict, not semantic conflict. The difference
between the two can be shown with a simple example: consider two
transactions, $T$ and $U$, that access the same shared counter
initially holding the value $0$. Transaction $T$ checks if the value
of the counter is less than $100$ and, if yes, performs some
computation. Transaction $U$ increments the value of the counter from
$0$ to $1$. If $T$ and $U$ are executed concurrently there may be
physical conflict, because $T$ reads from a transactional variable to
which $U$ writes, but there is no semantic conflict because the value
of the counter is still less than $100$, and so the outcome of $T$
does not change.

\subsection{Aborts and retries}
\label{sec:aborts-using-panics}

In the GVSTM, the only reason for a transaction to abort or retry ---
discard its progress so far and restart its computation --- is if it
conflicts with another transaction. This is necessary to maintain the
correctness properties of the STM. This behaviour should not be
exposed to users --- the STM should automatically retry when it
detects a conflict.

Some STMs allow users to explicitly abort or retry
transactions. Because STMBench7 does not use these operations I do not
have a meaningful way of evaluating them, and so I decided not to add
them to the GVSTM implementation. That being said, my design makes the
addition of these features simple, as described in
Section~\ref{sec:impl:extensions}.

\subsection{Lifetime of a transaction}
\label{sec:lifetime-transaction}

The lifetime of a transaction can be divided into four main stages:

\begin{description}
\item[Start] The transaction is created, along with its arguments and
  any bookkeeping necessary.
\item[Execution] The transaction performs its computation, possibly
  including reads and writes to transactional variables.
\item[Validation] A check is made to guarantee that the transaction
  does not cause a conflict. If the transaction fails the check it
  typically retries. If the transaction passes the check it commits.
\item[Commit] The transaction is now successfully completed. The work
  to be done here depends on the algorithm used --- this is explained
  in Section~\ref{sec:impl:diff-meth-deal}.
\end{description}

\subsection{Different methods of dealing with conflicts}
\label{sec:impl:diff-meth-deal}

STMs can be classified based on when validation is performed and when
writes to transactional variables are installed:

\paragraph{Deferred update.} The writes to transactional variables are
installed only at commit-time. That is, when a transaction writes to a
transactional variable it does not change the value stored in the
transactional variable immediately. Instead, it stores the written
value in a shadow-copy private to the transaction. Then, if the
transaction terminates successfully, it installs the values stored in
its shadow-copies in the transactional variables, at which point the
new values become globally visible. This increases the amount of work
done at commit-time, but makes aborting a transaction very simple: the
new values are private so they can simply be discarded.

\paragraph{Direct update.} Writes to a transactional variable
immediately install the new value in the globally accessible
transactional variable. At commit-time there is no work necessary to
install the new values, but aborting is more complex. Because the new
values are already installed, it is necessary to roll-back the changes
made. When one transaction aborts, all other transactions that have
read the results of a write made by the aborting transaction must also
abort. This causes cascading aborts, which waste large amounts of
computation.

\paragraph{Lazy conflict detection.} Validation is done only after the
execution stage of the transaction has completed, immediately before
the commit stage. This has the potential to waste a lot of
computation, because transactions already destined to abort will run
all remaining computation. On the other hand, the overhead of
individual reads of transactional variables can be much lower when
compared to eager conflict detection.

\paragraph{Eager conflict detection.} Validation is done at every read
of a transactional variable. This often implies that a direct update
scheme is used. If, for example, one transaction reads a transactional
variable to which a concurrently executing transaction has already
written, the reading transaction automatically aborts. This has the
potential of unnecessarily aborting transactions: in the previous
example, aborting is necessary only if the writing transaction commits
successfully.

\section{STM interface in Go}
\label{sec:design-decisions}

In this section I present the design for a general STM interface in
Go, based on the features of the language described in
Section~\ref{sec:prep:research}. Listing~\ref{lst:STMInterface} shows
this interface and Listing~\ref{lst:counter} shows an example of a
transactional counter implemented using it.

\begin{Listing}[hbtp]
\begin{lstlisting}
type TVar interface {}

type Transaction interface {
	Load(tVar TVar) interface{}
	Store(tVar TVar, value interface{})
}
\end{lstlisting}

  \mycaption{The STM interface.}{This represents the minimum
    functionality that an STM should be able to provide in Go.}
  \label{lst:STMInterface}
\end{Listing}

\begin{Listing}[hbtp]
\begin{lstlisting}
type TransactionalCounter struct {
    value TVar
}

func NewTransactionalCounter() *TransactionalCounter {
    return &TransactionalCounter{ value: newTVar(0) }
}

func (c *TransactionalCounter) Increment(tx Transaction) {
    tx.Store(c.value, tx.Load(c.value))
}

func (c *TransactionalCounter) Get(tx Transaction) int {
    return tx.Load(c.value).(int)
}

func (c *TransactionalCounter) AtomicIncrement() {
    Atomic(func(tx Transaction) {
        tx.Store(c.value, tx.Load(c.value))  
    })
}

func (c *TransactionalCounter) AtomicGet() (value int) {
    Atomic(func(tx Transaction) {
        value = tx.Load(c.value).(int)    
    })
    return 
}
\end{lstlisting}

  \mycaption{A transactional counter.}{This example shows both
    transactional functions and atomic versions of those functions.}
  \label{lst:counter}
\end{Listing}


\subsection{Typing}
\label{sec:typing}

An STM should be able to synchronise access to variables of arbitrary
types. As mentioned in Section~\ref{sec:prep:polymorphism}, Go does
not support generic programming, but supports polymorphism in the form
of interfaces. Because all types must be supported, the functions to
store to or load from a transactional variable must operate with
values of the empty interface type.

Because the load of a transactional variable returns an
\goType{interface\string{\string}} type, the user must cast the
returned value to the expected type. This prevents static type
checking of values in transactional variables, and hence increases the
burden on the programmer to guarantee that values loaded from
transactional variables have the correct type. Sadly, this is
presently the only solution that supports all types.

\subsection{Transaction representation}
\label{sec:expl-trans-objects}

All operations on transactional variables should be associated with an
existing transaction. This means that any part of a program that
attempts to perform an operation on a transactional variable must have
access to the object representing the transaction with which the
operation is associated. In the JVSTM, for example, this is achieved
by storing that object in thread-local storage. Loads and stores of a
transactional variable then access this thread-local storage to make
any bookkeeping necessary. However, as mentioned is
Section~\ref{sec:prep:thread-locals}, Go does not support thread-local
storage.

Without thread-local storage, all the variables accessible inside a
function must be either global variables or arguments passed to the
function. The bookkeeping data of transactions should not be globally
accessible, because that would allow users to accidentally violate the
isolation guarantees provided by the STM. Not only that, it would be
extremely difficult for the load and store operations of a
transactional variable to determine with which transaction the
operation should be associated. This means that, to be able to perform
an operation on a transactional variable, functions must receive a
transaction object as an argument, and pass it to the functions that
perform the transactional variable operations.

The inner structure of transaction objects is likely to be specific to
each STM implementation and only code internal to the STM
implementation should be able to access it. For these reasons, users
of an STM should not be able to create or modify transaction objects.

\subsection{``Transactional'' functions}
\label{sec:trans-funct}

The fact that functions operating on transactional variables must
receive a transaction object as an argument leads to the existence of
a ``contagious'' property of functions. This property applies to all
functions that must receive a transaction object as an argument and
can be defined recursively:

\begin{enumerate}
\item A function is transactional if it operates on a transactional
  variable.
\item A function is transactional if it calls a transactional function
  without surrounding said call in a call to \goFunc{Atomic}.
\end{enumerate}
Defining this property has some subtle advantages. Firstly, the
inclusion of a transaction in the parameters of a function clearly
marks the function as transactional. For this reason, I adopted the
convention of always passing the transaction as the first argument of
any transactional function, to make it more visible that the function
is transactional. Secondly, because creation of transactions is
restricted to the STM implementation, a user cannot perform operations
on transactional variables without having a valid transaction created
by the STM code.

\subsection{``Atomic'' execution}
\label{sec:atomic-function}

In this dissertation, and indeed most of the literature on STMs, it is
usual to say that transactions occur ``atomically''. This is somewhat
of a misnomer, because the term is not used to entail only the
atomicity property described in
Section~\ref{sec:prep:techn-requ}. Instead, atomic execution is taken
to mean ``execution according to all the correctness properties
claimed by the STM in question''. In the case of the GVSTM, and hence
throughout this dissertation, that property is opacity, as also
described in Section~\ref{sec:prep:techn-requ}.

A user of an STM should be able to define and atomically run a
transaction. According to the definition of transactional functions
introduced in Section~\ref{sec:trans-funct}, it makes sense to
represent a transaction to be executed as a transactional
function. Due to Go's treatment of functions as values, atomic
execution can be achieved by passing a transactional function as an
argument to some function \goFunc{Atomic}, which handles any necessary
bookkeeping.

I did not include this function in the STM interface because the
characteristics of STMs can somewhat vary. In particular, the
signature required by the \goFunc{Atomic} function will depend on the
bookkeeping necessary: some STMs may, for example, require the
\goFunc{Atomic} function to take as an argument whether the
transaction to be executed is read-only or read-write. An example use
of this function is shown in Listing~\ref{lst:counter}.

\section{GVSTM}
\label{sec:impl:gvstm}

In this section I describe the implementation of the GVSTM. Most
aspects of the implementation are similar to those of the JVSTM, but I
also describe the design work necessary to adapt the algorithm to Go's
features.

\subsection{Versioned data structures}
\label{sec:impl:vers-data-struct}

The JVSTM uses multi-version data structures, called versioned boxes,
to implement transactional variables~\cite{VBox}. A versioned box
contains a history of the values installed in the transactional
variable. That is, a sequence of version-value pairs, where the
version is the logical timestamp at which the value was installed in
the transactional variable. This logical timestamp is the
serialisation order number of the transaction that stored the
corresponding value.

\paragraph{Semantics.} The key property of versioned boxes is that
their operations semantically appear to occur at arbitrary logical
timestamps:
\begin{itemize}
\item A load of a versioned box is made with an associated
  read-timestamp and returns the most recent value that was not
  installed after the given timestamp.
\item New values are installed in a versioned box with a given
  commit-timestamp, representing writes of the given values to the
  transactional variable at the given timestamp.
\end{itemize}

\paragraph{Implementation.} Versioned boxes are implemented using a
linked list of version-value pairs ordered in reverse version number
order (newest first). The elements in the list are called versioned
bodies. A version box is simply a wrapper for this linked list. A
graphical representation of this structure is shown in
Figure~\ref{fig:box-and-bodies}.

\begin{figure}[hb]
  \centering
  \begin{tikzpicture}
    \drawVBox{B}{b1/2/87,b2/1/23,b3/0/0}
  \end{tikzpicture}
  \mycaption{The versioned box data structure.}{A load with version
    number 0 to 22 will yield value 0. A load with version number 23
    to 86 will yield value 1. A load with version number larger than
    86 will yield value 2.}
  \label{fig:box-and-bodies}
\end{figure}
A read of a versioned box traverses the list of bodies until it finds
a version no greater than the timestamp given and returns the value
associated with that timestamp. The installation of a value in a
versioned box adds a new body to the list of bodies --- in the GVSTM
the installation of a value in a versioned box is guaranteed to be
made with a version number greater than all version numbers already
present in the box, so this only requires adding the new body to the
head of the list.

\subsection{Algorithm overview}
\label{sec:algorithm-overview}

According to the classification of STMs described in
Section~\ref{sec:impl:diff-meth-deal}, the GVSTM performs lazy
validation and deferred updates. This means that validation and
installation of new values are done only at commit-time. To do this,
the GVSTM uses transaction objects that store the bookkeeping
necessary and are created when the transaction starts. Assume for now
that all transactions perform both reads and writes of transactional
variables.

\paragraph{Transaction objects.} Each transaction object maintains a
read-timestamp, a read-set, and a write-set:

\begin{description}
\item[Read-timestamp] \hfill\\
  The read-timestamp is used to read from versioned boxes during the
  execution of the transaction. When the transaction is created, the
  read-timestamp is read from a global logical clock, which counts all
  the transactions that have committed. This means that the
  read-timestamp of every executing transaction is the serialisation
  order number of the latest transaction to have committed when the
  transaction started.
\item[Read-set] \hfill\\
  The read-set contains all the versioned boxes read by the
  transaction. When the transaction object is created, this set is
  empty.
\item[Write-set] \hfill\\
  The write-set of the transaction contains the shadow-copies of
  transactional variables --- it is a map from versioned boxes to the
  latest values the transaction has written to them. When the
  transaction object is created, the map is empty.
\end{description}
The transaction objects are used when reading and writing to versioned
boxes --- a read adds the box to the read-set; a write of a value adds
the box-value pair to the write-set. At commit-time all the entries in
the write-set are installed in the versioned boxes.

% \paragraph{Nesting.} A transactional function can call other
% transactional functions. In this scenario, the former is called the
% parent and the latter are called the children. A parent passes the
% transaction object it received as argument in all calls to its
% children. By induction, all descendants of a root transactional
% function, which is passed as an argument to the \goFunc{Atomic}
% function, operate on the same transaction object. This produces flat
% nesting: all descendants of a transactional function validate and
% commit with the root transaction. There are other nesting
% schemes~\cite{diegues2012review}, but they are much more complex and
% beyond the scope of this project.

\subsection{Validation and commit algorithms}
\label{sec:valid-comm-algor}

Here I describe the validation and commit algorithms used by the
GVSTM, and how the commit algorithm was adapted from that of the JVSTM
to reduce the commit-time bottleneck.

\paragraph{Commit lock.} Validating a transaction concurrently with
the installation of changes on transactional variables by another
transaction is extremely complex. For this reason, the original
implementation of the JVSTM~\cite{VBox} uses a global commit lock to
serialise the validation and commit process: when a transaction
terminates it acquires the lock, validates and commits, then releases
the lock. Later work extended the JVSTM to have a lock-free commit
algorithm~\cite{fernandes2011lock}. The implementation of this
extension would make for an interesting Part II project on its own
right, so I decided to implement the lock-based commit algorithm.

\paragraph{Commit algorithm.} The commit algorithm of the GVSTM simply
installs all the written values in the corresponding versioned
boxes. At the start of the commit, a commit timestamp is calculated by
adding one to the commit-timestamp of the latest committed
transaction. The commit-timestamps of transactions dictate their
serialisation order. Each value installed in a versioned box is
installed with this commit-timestamp as its version number.

\paragraph{Commit-time bottleneck reduction.} The commit algorithm is
run sequentially, whilst transaction execution is run in
parallel. According to Amdahl's law~\cite{Amdahl}, this makes the
commit algorithm the sequential bottleneck of the GVSTM, especially as
the number of transactions run in parallel increases. It is hence
desirable to shorten this bottleneck as much as possible.

As mentioned in Section~\ref{sec:impl:vers-data-struct}, the
installation of a value in a versioned box consists of adding a new
body to the head of the list of bodies. The JVSTM declares the fields
of a body \javaKeyword{final} and fills them in immediately before
adding the body to the linked list. Java's memory model then
guarantees that the initialisation of the fields of a body occurs
before the addition of the body to the list. This prevents a race
condition between a committing transaction and a reading transaction,
which would cause the reading transaction to see an uninitialised
body.

Go does not have a construct with memory model semantics equivalent to
Java's \javaKeyword{final} variables, so the GVSTM must use a
synchronising memory operation when adding a body to a list of
bodies. This also means that the bodies no longer have to be created
at commit time. Instead, they are created and added to the write-set
of a transaction when it first writes to a transactional
variable. This shifts the overheads of allocating memory for the
versioned bodies from the sequential commit-time algorithm to the
parallel execution of concurrent transactions, reducing the length of
the bottleneck of the algorithm.

\paragraph{Validation algorithm.} The validation algorithm of the
GVSTM determines if the validating transaction can be serialised
directly after the last committed transaction. For this to be
possible, the transaction must not conflict with any committed
transaction. As described in Section~\ref{sec:impl:conflicts}, a
physical conflict occurs when a read and a write of a transactional
variable occur in concurrent transactions. We can then analyse the two
possible cases:

\begin{description}
\item[Read by a committed transaction, write by the validating transaction.] \hfill\\
  This does not cause a conflict --- the write has not been installed
  yet, so the reading transaction must have read an earlier
  value. This is consistent with the serialisation order of commits:
  the committed transaction is serialised before the validating
  transaction.
\item[Write by a committed transaction, read by the validating transaction.] \hfill\\
  This may cause a physical conflict: because the validating
  transaction is serialised after the committed transaction, it should
  have read a value at least as recent as the committed
  transaction. However, because the validating transaction reads using
  its read-timestamp, it will only have read a value at least as
  recent as the committed transaction if the commit occurred no later
  than the read-timestamp of the validating transaction. If this is
  not the case, the validating transaction has violated strict
  serialisability by reading a stale value, and hence must abort.
\end{description}
The validation algorithm then only needs to check that, in every
versioned box in the read-set of the validating transaction, there is
no value installed later than the read-timestamp of the validating
transaction. If there is, the transaction must abort. If there is not,
the transaction may commit without causing conflict.

\subsection{Read-only transactions}
\label{sec:impl:read-only-trans}

The validation algorithm is necessary to ensure that transactions
appear to occur atomically. In particular, the validation algorithm of
the GVSTM checks if the transaction can appear to occur atomically at
commit time. It is not necessary in the general case that transactions
appear to occur at commit time --- but introducing this restriction
keeps the validation and commit algorithms simple.

An important observation is that, due to the use of versioned boxes,
all reads by a transaction appear to occur at the same time --- the
read-timestamp issued at the start of the transaction. A transaction
that only performs reads of versioned boxes --- a read-only
transaction --- is then by construction atomic, and can always be
serialised at its read-timestamp. Because read-only transactions are
always serialisable, there is no need for them to validate. Because
read-only transactions do not write to transactional variables, the
commit algorithm does nothing. As such, read-only transactions are
allowed to bypass the validation and commit stages entirely while
preserving the correctness of the STM. Because of this, the GVSTM
handles read-only transactions differently:

\begin{itemize}
\item The transaction object does not contain a read-set, because
  validation is unnecessary. This also removes the overhead of adding
  the versioned box to the read-set when a transactional variable is
  first read, so individual reads of versioned boxes are also more
  efficient.
\item The transaction object does not hold a write-set, because the
  transaction makes no write operations.
\item Read-only transactions cannot abort, because they are
  serialisable by construction.
\item Read-only transactions do not need to wait to acquire the commit
  lock, so given otherwise equal conditions their performance is
  independent of contention in the commit lock. This gives guarantees
  on the latency of read-only transactions regardless of the presence
  of inter-conflicting read-write transactions.
\end{itemize}

\paragraph{Always start as a read-only transaction.} It is not
desirable to require a user to distinguish read-only transactions. One
reason for this is that it is not always possible to determine ahead
of time if a transaction will be read-only. It may be, for example
that a transaction will perform a write of a transactional variable if
some condition holds, but this condition cannot be determined before
the transaction starts. In these cases, the user would have to default
to declaring the transaction as a read-write transaction and
potentially miss out on the increased performance of read-only
transactions. This approach is also more error prone: a mislabelling
of a transaction may violate the invariants of the STM. For these
reasons, the GVSTM attempts to execute all given transactions as
read-only transactions. If the transaction attempts to perform a write
operation it aborts and retries as a read-write transaction.

\paragraph{Write in a read-only transaction.} Evidently, the behaviour
just described should not be exposed to the user. When a read-only
transaction attempts to write, control should return to the
\goFunc{Atomic} function automatically. This is achieved by using a
call of \goFunc{panic}.

It is interesting to note that write-only transactions also never fail
validation, because a set of writes can always be serialised after any
set of transactions. In practice, however, write-only transactions are
very uncommon, so not worth optimising.

\subsection{Garbage collection of old versioned bodies}
\label{sec:impl:garbage-collection}

As the reader may have noted, writing to versioned boxes increases the
size of the linked list they store. This means that a program using
the GVSTM will slowly run out of memory by filling it with old
versioned bodies. This of course is not acceptable, so an algorithm to
reclaim old bodies must be employed. This is by far the most complex
aspect of the GVSTM implementation --- the original description of the
lock-free algorithm for the JVSTM is six pages
long~\cite[Section~4.4.7]{cachopo2007phd}.  However, due to the page
limit of this dissertation I will have to limit my description to a
short overview, and I will not be discussing all the race conditions
that must be avoided by an implementation of the algorithm. The
interested reader can examine my implementation of the GVSTM or read
the original description of the algorithm cited above.

\paragraph{Active transaction records.} An active transaction record
holds the commit-timestamp of a committed transaction and the set of
versioned bodies created by the corresponding transaction. The record
also holds a counter of currently executing transactions whose
read-timestamp is equal to the timestamp of the record --- that is,
all transactions that are semantically reading at the same point in
time as the transaction corresponding to the record committed. When a
transaction starts, it increments the counter of the record
corresponding to its read-timestamp. When a transaction terminates ---
either through a commit or an abort/retry --- it decrements the
counter.

\paragraph{Linked list of records.} The GVSTM keeps a linked list of
transaction records in reverse timestamp order. When a transaction
commits, it must create a new active transaction record and add it to
the head of the list. Read-only transactions do not need to do this,
but they must increment and decrement counters appropriately.

\paragraph{Cleaning bodies.} When all executing transactions have
started after a particular timestamp, the bodies of the corresponding
record can be cleaned. That is, the bodies stored in the record can be
freed to be reclaimed by the OS. Both Java and Go are garbage
collected, so in both cases this means simply removing the bodies from
the corresponding lists --- the runtime garbage collector takes care
of the rest. In practice, determining that all executing transactions
have started after a certain timestamp while avoiding race conditions
is rather complex --- again, the interested reader is welcome to read
the original description of the algorithm.

\subsection{Extensions}
\label{sec:impl:extensions}

Here I discuss some extensions that could be made to the GVSTM. I did
not implement these extensions partly because of the time restrictions
on the project, and partly because STMBench7 does not leverage any of
them, so I would not be able to evaluate them
meaningfully. Nevertheless, these features increase the expressiveness
of an STM and could be implemented in future work.

\paragraph{Abort and retry semantics.} As mentioned in
Section~\ref{sec:impl:read-only-trans}, a call to \goFunc{panic} is
used to abort a read-transaction and retry its execution as a
read-write transaction. In this case, the call to \goFunc{panic} takes
as an argument a value denoting an attempted write in a read-only
transaction. Using the same principle, the \goFunc{panic} function
could be used with other values to denote an explicit abort or retry
by the user. The GVSTM would then distinguish between these values and
abort or retry as required. This is a very simple addition: the only
modifications required are a change in the atomic function to handle
these values and the addition of functions \goFunc{Abort} and
\goFunc{Retry} exposed to the user, which are wrappers for the calls
of \goFunc{panic}. When preparing my project I had planned to
implement this extension, but ultimately decided against it due to the
lack of its use in STMBench7.

\paragraph{Different nesting semantics.} The GVSTM presently only
supports flat nesting. It could be an interesting Part II, or indeed
Part III, project to implement one or more other nesting
schemes~\cite{diegues2012review}.

\paragraph{Side effects as monads.} The GVSTM only handles accesses to
transactional variables. If a transaction creates other types of side
effects, such as printing to a file or channel communication, those
effects are not transactional. One approach to changing this would be
to represent these effects as monads, in the form of functions kept by
the transaction object. On commit, each of these monads is
executed. This solution only handles cases in which the transaction is
producing output. Much more careful thinking is required in the case
where the transaction consumes some input --- it could require, for
example, the creation of transactional wrappers for channels and I/O
streams, which could be made available as a library and could increase
the appeal of the GVSTM to software engineers.

\section{STMBench7}
\label{sec:impl:stmbench7}

In this section I describe my implementation of STMBench7, with a
focus on its software engineering aspects.

\subsection{Collection of results}
\label{sec:impl:collection-results}

In my project proposal (Appendix~\ref{cha:project-proposal}) I set out
to produce an implementation of STMBench7 in the form of files to be
used by Go's \texttt{test} tool. However, after examining the Java
source code of the benchmark, I noted that it produced more detailed
statistics than Go's \texttt{test} tool for this particular
application. As such, I amended the format of my STMBench7
implementation to be a single Go executable, which more closely
resembles the design of the Java implementation.

To make it easier to collect the results of a large number of
benchmark runs, I made the benchmark output the generated statistics
to a file as well as the console. Each run of the benchmark creates a
new file, whose name is the time at which the benchmark was run and
which contains information about the parameters used.

To automate the collection of results of multiple runs of the
benchmark I made my implementation accept the parameters of the
benchmark as command line flags and created a shell script to run the
benchmark with a variety of parameters. This should not be done inside
the Go executable to guarantee that runs of the benchmark are
independent --- no need to garbage collect the results of previous
runs, for example.

\subsection{Data structures}
\label{sec:impl:data-structures}

The data structure used by the benchmark represents the data structure
that would be used by a Computer Aided Design application. As
mentioned in Section~\ref{sec:prep:oop}, object semantics are often
useful, and this is the case throughout STMBench7. In the rest of this
section I will refer to elements of the STMBench7 implementation as
objects, even though Go is not object oriented, to mean that the
elements are represented using the interface pattern described in
Section~\ref{sec:prep:oop}. All the data structure interfaces
described here need to be implemented using each synchronisation
mechanism.

\paragraph{Design library.} The design library is a set of composite
parts. Each composite part has one document and a graph of atomic
parts. The atomic parts are connected by connection objects. The
composite part also has a pointer to the root of the graph.

\paragraph{Module.} A module has one manual and a tree of
assemblies. Assemblies at the leaves of the tree are called base
assemblies. There is a many-to-many relation between base assemblies
and composite parts. All other assemblies are complex assemblies.

All objects in the data structure --- the design objects --- also
contain references to their parent, so for example it is possible to
get the parent composite part of any given atomic part, and the root
complex assembly of any assembly. It is worth noting that in STMBench7
only one module is used. A visual representation of the data structure
is shown in Figure~\ref{fig:stmbench7}.

\begin{figure}[h]
  \centering \includegraphics{stmbench7.pdf} \mycaption{The STMBench7
    data structure.}{This diagram is copied from the original
    STMBench7 paper~\cite{STMBench7}}.
  \label{fig:stmbench7}
\end{figure}

\paragraph{Backend data structures.} The benchmark data structures are
implemented using backend data structures. To increase the fairness
between synchronisation mechanisms I kept these implementations as
similar as possible. This guarantees that any differences in
performance are due to the synchronisation mechanism and not to the
backend data structure implementation. Unfortunately the
implementation used is naive and not very inefficient. It is worth
drawing attention to two of the backend data structures:

\begin{description}
\item[ID pool] An ID pool is a finite set of unique identifiers for a
  particular type of object. There is an ID pool for documents, one
  composite parts, etc. When an object is created it gets an ID from
  the corresponding pool, if any are available. When an object is
  destroyed it returns its ID to the pool.
\item[Index] An index is a map of some key type to all the objects of
  a particular type. Most indexes have IDs taken from an ID pool as
  keys, but there is also an index of documents indexed by their
  titles and index of composite parts indexed by build date. When an
  object is created or destroyed it is added or removed, respectively,
  from the corresponding index or indices.
\end{description}

\subsection{Operations}
\label{sec:impl:operations}

STMBench7 supports four types of operations on its data structure,
which are summarised below. It is important to note that operations
can fail due to operation logic. This is not due to transactions
aborting or conflicting, but for example that ID pools are empty or
that a random traversal reached a base assembly with no composite
parts. This means that when looking at benchmark results it makes
sense to look at the total throughput and not only at the throughput
of successful operations.

\paragraph{Long traversals.} Long traversals traverse very large
numbers of objects. Most long traversals traverse the whole tree of
assemblies, and some also traverse the graph of atomic parts of all
composite parts. Most long traversals have a read-only and a
read-write variant. Long read-write traversals only perform write
operations on the attributes of atomic parts or documents --- they do
not modify structure.

\paragraph{Short traversals.} Short traversals reach much smaller
numbers of objects --- instead of traversing the whole tree of
assemblies, most short traversals take a random path from the root
assembly to a composite part or from an atomic part to the root
assembly. Most short traversals have read-only and read-write
variants, and the write operations are only on attributes of design
objects.

\paragraph{Short operations.} Short operations do not traverse the
data structure at all. Instead, they use the indexes to find all
objects of a type or find a random object. Again, most short
operations have read-only and read-write variants, and the write
operations are only on attributes of design objects.

\paragraph{Structure modification operations.} Structure modifications
make major changes to the data structure. They add and remove
assemblies and composite parts and create and remove links between
them. This conflicts with all traversals, so the inclusion of
structure modifications in the benchmark workload severely impacts
performance, as shown in Section~\ref{sec:impl:workloads}.

\subsection{Design patterns}
\label{sec:impl:design-patterns}

The Java implementation of STMBench7 makes extensive use of object
oriented design patterns~\cite{GoF} to make it easy to extend the
benchmark with additional synchronisation approaches, such as
STMs. One of the challenges of porting the benchmark to Go was
understanding these patterns and how they can be adapted to a
non-object oriented language, and it was a good exercise of software
engineering skills. The most prominent patterns are described below.

\paragraph{Command.} Operation executors are an implementation of the
command pattern. Operation executors handle any top-level
synchronisation necessary before executing an operation. In the case
of the coarse-grained locking approach this consists of acquiring the
global read-write lock, in a mode dependent of whether the operation
to be executed is read-only or read-write. The operation executor for
the medium- grained locking approach is much more complex: a large
number of locks must be acquired in a specific order, according to
which operation is being executed. Writing this executor is rather
error prone, as the slightest mistake is likely to cause deadlock or
race conditions. The GVSTM operation executor, on the other hand,
simply wraps the operation to be executed in a call to the
\goFunc{Atomic} function.

\paragraph{Factory method and abstract factory.} STMBench7 provides
interfaces for all its benchmark and backend data structures, which
are used throughout the benchmark. Each synchronisation mechanism
provides its own implementations of these interfaces, along with the
corresponding factory methods and abstract factories. This layer of
abstraction makes it simple to, for example, change the implementation
of the backend data structures without touching the rest of the
codebase.

\paragraph{Builder.} Builders are used to create and destroy the
benchmark data structures while respecting the invariants of the
benchmark. They encapsulate the addition and removal of objects from
the corresponding indexes as well as the creation of other objects
associated with the object being created, such as the document of a
composite part and the children assemblies of a complex assembly.

\medskip

These patterns make the addition of new synchronisation approaches to
the benchmark simple: the new synchronisation approach must only
provide implementations of the data structures, an operation executor
and add its abstract factories to the main file. There is no need to
change any of the benchmark logic, such as its operations and
builders.

\subsection{Testing}
\label{sec:impl:testing}

As with any software engineering project, testing is important to
guarantee that my implementations of both the GVSTM and STMBench7 are
correct. The original benchmark implementation included both invariant
tests on its data structures and opacity tests. Here I explain my
reasoning about what tests should be included in my implementation.

\paragraph{Invariant tests.} The invariant tests of STMBench7 check
that both the benchmark and backend data structures are in a
consistent state. I implemented these tests as soon as I had
implemented the factories and builders of the data structures, which
proved to be useful: the tests helped me find a couple of bugs I had
overlooked, and allowed me to fix them before beginning to implement
the operations of the benchmark, which would have caused much more
complex errors. I kept running these tests as I implemented the
operations, which made it much more efficient for me to debug my code.

\paragraph{Opacity tests.} The opacity tests of STMBench7 check that
the execution of the benchmark by an STM satisfies the opacity
property described in Section~\ref{sec:prep:techn-requ}. The GVSTM
algorithm is the same as that of the JVSTM, whose opacity property has
already been shown. Furthermore, bugs in the GVSTM implementation
would cause large errors in any application using it. These errors
would then cause the invariant tests to flag the error, so the opacity
tests give me no new information.

Not only that, the opacity tests rely on retracing a concurrent
execution serially, including the random short traversals. The Java
implementation relies heavily on thread-local random state to achieve
this. However, as discussed in Section~\ref{sec:prep:thread-locals},
Go does not support thread-local storage, so implementing these tests
would require a significantly different approach to the one used in
Java --- a very substantial engineering effort for no tangible benefit
to this project.

\subsection{Extensions}
\label{sec:impl:possible-extensions}

Here I discuss some extensions that could be made to my STMBench7
implementation. Most of them focus on making the benchmark results
more representative of real-world applications.

\paragraph{Implementing all 45 operations.} In my project proposal I
set out to implement only a subset of the original 45 operations of
STMBench7, and listed implementing all the operations as a possible
extension. In my project I achieved this extension goal. Although
implementing the benchmark as a whole was a much more ambitious goal
than I had expected, the addition of the remaining operations by
itself was reasonably simple thanks to the modular architecture of the
benchmark.

\paragraph{Efficient backend data structures.} As mentioned in
Section~\ref{sec:impl:data-structures}, the implementations of the
backend data structures using locking approaches and STM are similar
to increase the fairness of the benchmark. The implementation in
question is very inefficient, because the data structure must be
copied on write to prevent concurrent access. A very valuable
extension would be to provide more efficient implementations of the
backend data structures. In the case of locking this would only
involve removing the copying operations. In the case of the GVSTM this
would involve the creation of complex versioned data structures such
as sets and maps. The JVSTM provides this as part of a library. The
data structures are based on persistent data
structures~\cite{PurelyFunctional}. The creation of such a library to
be distributed with the GVSTM would also make it much more appealing
to software engineers.

\paragraph{Containerising.} One of the strongest appeals of STMs is
that they scale much better than other approaches to large numbers of
cores. During my project I collected results by running the benchmark
on my laptop only, but it would be interesting to run the benchmark on
server class machines. To make this easier, it would be useful to
create an STMBench7 container to facilitate deployment on a cloud
computing platform.

\paragraph{Rewrite the benchmark to be fairer.} The method to create
and register a complex assembly is unfair to STMs: if the ID pool for
either complex or base assemblies is exhausted the method undoes all
its work. This involves a lot of operations on backend data
structures. Some STM implementations, such as the GVSTM extended with
abort and retry semantics (Section~\ref{sec:impl:extensions}), could
simply abort or retry when they detect such an error, which would be
much more efficient.

\section{Repository overview}
\label{sec:impl:repository-overview}

One of my goals when proposing my project was to use it as a step
towards producing an open source library providing STM functionality
in Go. In order to evaluate my STM implementation, my project also had
to include the implementation of a benchmark for STMs. Because I
wanted this benchmark to be usable by other STM implementations, I
also needed to define an interface for STMs in Go. These three
``modules''~\cite[Section~1.1]{SoftwareArchitecture} of the project
should not necessarily be part of the same repository --- a software
engineer may want to use only the GVSTM, or care only about the
interface to produce their own STM implementation. For this reason,
the three modules should not necessarily be kept together in the long
run. In the scope of this project, however, it is much easier to
handle code submission and dependency management in a single
repository, so that is how I have structured my project. The
repository holding the source code of my project has one directory for
each of the modules. Their contents are summarised below.

\paragraph{STM interface.} The STM interface defined in this project
is reproduced fully in Listing~\ref{lst:STMInterface}.

\paragraph{GVSTM.} The implementation of the GVSTM is reasonably short
--- less than 300 lines of code. That being said, the algorithm being
implemented is rather complex, especially in avoiding race conditions
in the garbage collection of old bodies. A good understanding of the
algorithm is necessary to understand the implementation of the
transaction objects and the active transaction records. The
implementation of versioned boxes and versioned bodies is reasonably
well contained.

\paragraph{STMBench7.} The STMBench7 benchmark is by far the largest
part of this project in terms of lines of code --- approximately
5000. The structure of the benchmark is described in
Section~\ref{sec:impl:stmbench7}, and the organisation of source files
is made to resemble that of the Java implementation. Future versions
of my implementation may change this. Although I wrote all code
submitted on my own, my STMBench7 implementation is mostly a
translation of the Java version, with modifications to use the
features of Go and the STM interface I defined.

% \begin{figure}[h]
%   \centering \includegraphics{cuarms.pdf} \mycaption{Test
%   image.}{Kindly provided with the CL template.}
%   \label{fig:example}
% \end{figure}

% \begin{table}[h]
%   \centering
%   \begin{tabular}{| c | c |}
%     \hline
%     Float type & Working? \\
%     \hline
%     Figure & Check \\
%     Table & Check \\
%     Listing & Check \\
%     \hline
%   \end{tabular}
%   \mycaption{Test table.}{Shows whether the different types of
%   floats used are typeset as expected.}
%   \label{tbl:example}
% \end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Evaluation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Evaluation}

In this chapter I recall the success criteria of the project and
describe how they were achieved
(Section~\ref{sec:eval:success-criteria}). I give quantitative results
of benchmarking the GVSTM with STMBench7
(Section~\ref{sec:eval:benchmark-results}) and a qualitative
comparison of using locking approaches and the GVSTM to implement
STMBench7 (Section~\ref{sec:eval:ease-use}).

\section{Success criteria}
\label{sec:eval:success-criteria}

All the success criteria of the project were met, as well as the
extension goal of completing the implementation of STMBench7. In this
dissertation I also discuss extension goals for which design work was
made, but whose implementation would entail too large a time
investment to be included in this project. Below I summarise the goals
set out in my project proposal (Appendix~\ref{cha:project-proposal})
and specify how they were met.

\begin{description}
\item[To have a working implementation of the GVSTM.] \hfill
  \begin{itemize}
  \item Transactions appear to occur atomically and in isolation from
    the rest of the program, as demonstrated by the fact that the
    invariant tests of STMBench7 complete successfully. The GVSTM also
    provides the stronger property of opacity, as described in
    Section~\ref{sec:prep:techn-requ}.
  \item Transactional functions are composable, as described in
    Section~\ref{sec:trans-funct}.
    % and provide flat
    % nesting semantics, as described in
    % Section~\ref{sec:algorithm-overview}.
  \item The invariant tests of STMBench7 show that the GVSTM
    implementation is correct, as discussed in
    Section~\ref{sec:impl:testing}.
  \end{itemize}
\item[To have a partial implementation of STMBench7.] This goal has
  been exceeded, in that I have completed the STMBench7
  implementation.
  \begin{itemize}
  \item All the operations of STMBench7 have been implemented, and
    results collected from a variety of workloads. These results are
    summarised in Section~\ref{sec:eval:benchmark-results}.
  \item As discussed in Section~\ref{sec:impl:collection-results}, the
    original aim of structuring the benchmark as test files supported
    by Go's \texttt{test} tool was amended upon further
    inspection. Instead, the benchmark is a standalone executable file
    that produces more detailed statistics for STM evaluation.
  \end{itemize}
\item[To make a meaningful evaluation of the GVSTM.] \hfill
  \begin{itemize}
  \item In Section~\ref{sec:eval:benchmark-results} I examine the
    performance of my GVSTM implementation compared to that of coarse-
    and medium-grained locking approaches.
  \item In Section~\ref{sec:eval:ease-use} I draw on my personal
    experience of programming using the GVSTM and using locks to
    compare the usability of each approach.
  \end{itemize}
\end{description}

\section{Benchmark results}
\label{sec:eval:benchmark-results}

In this section I summarise the results obtained by running STMBench7
with the GVSTM and locking approaches. A detailed evaluation of the
GVSTM would include metrics such as the maximum latency of operations
--- particularly read-only operations --- as well as CPU utilisation
and the memory overhead of storing multiple versions. However, due to
the space restrictions on this dissertation, I will focus only on the
total throughput, in operations per second, of the GVSTM and locking
approaches using different workloads and number of goroutines.
Appendix~\ref{cha:stmb-example-outp} contains detailed results of one
run of STMBench7. Appendix~\ref{cha:benchm-meth} describes my
benchmarking methodology.

\subsection{Workloads without structure modifications}
\label{sec:impl:workloads}

In this section I show the results of benchmarking using three
workloads:

\begin{description}
\item[Read only workload] $100\%$ read-only operations
\item[Read-dominated workload] $90\%$ read-only operations
\item[Read-write workload] $60\%$ read-only operations
\end{description}
Long traversals, including long read-write traversals, are enabled;
structure modifications are disabled. The ratios of each kind of
operation are the default values defined by STMBench7. Due to the
inefficient implementations of the backend data structures
(Section~\ref{sec:impl:data-structures}) I reduced the number of
composite parts to 50, to make the initialisation of the benchmark
less time consuming.

Figures~\ref{fig:throughput100},~\ref{fig:throughput90}
and~\ref{fig:throughput60} show the throughput of the three
synchronisation approaches in each of the workloads. Note that,
because of the benchmarking methodology used
(Appendix~\ref{cha:benchm-meth}) the error bars are barely visible in
most cases.

\begin{figure}[htb]
  \begin{tikzpicture}
    \begin{axis}[ legend style={legend pos=south east}, xlabel={Number
        of threads}, ylabel={Total throughput (op/s)}, ymin=0,
      width=\graphWidth]
    
      \addplot+[mark=x, cyan, densely dashed, error bars/.cd, y
      dir=both, y explicit] coordinates { (1,11055) +- (0,10)
        (2,20606) +- (0,45) (4,33690) +- (0,65) (8,36372) +- (0,98) };

      \addplot[mark=square, red, solid, error bars/.cd, y dir=both, y
      explicit] coordinates { (1,12751) +- (0,17) (2,23063) +- (0,59)
        (4,37271) +- (0,94) (8,38620) +- (0,79) };

      \addplot[mark=*, green, densely dotted, error bars/.cd, y
      dir=both, y explicit] coordinates { (1,12428) +- (0,4) (2,23029)
        +- (0,75) (4,37145) +- (0,134) (8,38817) +- (0,91) };
      
      \legend{GVSTM, Coarse-grained locking, Medium-grained locking}
    \end{axis}
  \end{tikzpicture}
  \mycaption{Total throughput of a read-only workload.}{}
  \label{fig:throughput100}
\end{figure}

\begin{figure}[htb]
  \begin{tikzpicture}
    \begin{axis}[ legend style={legend pos=south east}, xlabel={Number
        of threads}, ylabel={Total throughput (op/s)}, ymin=0,
      width=\graphWidth]
    
      \addplot[mark=x, cyan, densely dashed, error bars/.cd, y
      dir=both, y explicit] coordinates { (1,9417) +- (0,81) (2,16188)
        +- (0,134) (4,20707) +- (0,255) (8,18315) +- (0,393) };

      \addplot[mark=square, red, solid, error bars/.cd, y dir=both, y
      explicit] coordinates { (1,11414) +- (0,15) (2,14051) +- (0,3)
        (4,14574) +- (0,24) (8,14146) +- (0,16) };

      \addplot[mark=*, green, densely dotted, error bars/.cd, y
      dir=both, y explicit] coordinates { (1,11091) +- (0,14)
        (2,17206) +- (0,11) (4,23327) +- (0,11) (8,25812) +- (0,142)
      };
      
      \legend{GVSTM, Coarse-grained locking, Medium-grained locking}
    \end{axis}
  \end{tikzpicture}
  \mycaption{Total throughput of a read-dominated workload.}{}
  \label{fig:throughput90}
\end{figure}

\begin{figure}[htb]
  \begin{tikzpicture}
    \begin{axis}[ legend style={legend pos=south east}, xlabel={Number
        of threads}, ylabel={Total throughput (op/s)}, ymin=0,
      width=\graphWidth]
    
      \addplot[mark=x, cyan, densely dashed, error bars/.cd, y
      dir=both, y explicit] coordinates { (1,4898) +- (0,21) (2,5632)
        +- (0,101) (4,5154) +- (0,36) (8,4022) +- (0,35) };

      \addplot[mark=square, red, solid, error bars/.cd, y dir=both, y
      explicit] coordinates { (1,8496) +- (0,13) (2,8536) +- (0,20)
        (4,8507) +- (0,6) (8,8557) +- (0,35) };

      \addplot[mark=*, green, densely dotted, error bars/.cd, y
      dir=both, y explicit] coordinates { (1,8382) +- (0,5) (2,10360)
        +- (0,17) (4,11348) +- (0,17) (8,11668) +- (0,22) };
      
      \legend{GVSTM, Coarse-grained locking, Medium-grained locking}
    \end{axis}
  \end{tikzpicture}
  \mycaption{Total throughput of a read-write workload.}{}
  \label{fig:throughput60}
\end{figure}

As shown in Figure~\ref{fig:throughput100}, the throughput of all
synchronisation approaches in a read-only workload scales with the
number of cores used, and minimal additional throughput is achieved by
using simultaneous multithreading (SMT). Note that in pure read-only
applications no synchronisation is necessary.

Figure~\ref{fig:throughput90} represents the best use-case of STMs,
and of the GVSTM in particular. The read-dominated workload keeps the
rate of conflicts low, so the GVSTM scales almost as well as the
medium-grained locking approach, despite being much more simple and
general-purpose. The use of SMT slightly degrades performance, because
sharing a core causes individual transactions to have a higher
latency, and hence a higher chance to conflict.

Figure~\ref{fig:throughput60} shows the result of benchmarking a
read-write workload. The coarse-grained approach achieves the same
throughput regardless of the number of goroutines used, as the global
lock serialises operations. The medium-grained approach is able to
extract some throughput by using more goroutines, but the improvement
is minimal compared to the read-dominated approach. The GVSTM is able
to extract some throughput by using two goroutines instead of one, but
increasing the number of goroutines used degrades performance. This is
because the rate of conflicts increases, causing more transactions to
abort and waste computation. In absolute terms, the performance of the
GVSTM is significantly lower than that of both locking approaches,
because the overheads of read-write transactions in the GVSTM are
substantial.

\subsection{Introducing structure modifications}
\label{sec:struct-modif}

Figures~\ref{fig:sm90} and~\ref{fig:sm60} show the results of
benchmarking the read-dominated and read-write workloads with
structure modifications enabled.

\begin{figure}[htb]
  \begin{tikzpicture}
    \begin{axis}[ legend style={legend pos=south east}, xlabel={Number
        of threads}, ylabel={Total throughput (op/s)}, ymin=0,
      width=\graphWidth]
    
      \addplot[mark=x, cyan, densely dashed, error bars/.cd, y
      dir=both, y explicit] coordinates { (1,1747) +- (0,1) (2,1504)
        +- (0,29) (4,1134) +- (0,10) (8,631) +- (0,97) };

      \addplot[mark=square, red, solid, error bars/.cd, y dir=both, y
      explicit] coordinates { (1,1546) +- (0,13) (2,1721) +- (0,84)
        (4,1560) +- (0,18) (8,1800) +- (0,48) };

      \addplot[mark=*, green, densely dotted, error bars/.cd, y
      dir=both, y explicit] coordinates { (1,1582) +- (0,2) (2,1759)
        +- (0,31) (4,1663) +- (0,7) (8,1814) +- (0,26) };
      
      \legend{GVSTM, Coarse-grained locking, Medium-grained locking}
    \end{axis}
  \end{tikzpicture}
  \mycaption{Total throughput of a read-dominated workload with
    structure modifications.}{}
  \label{fig:sm90}
\end{figure}

\begin{figure}[htb]
  \begin{tikzpicture}
    \begin{axis}[ legend style={legend pos=south east}, xlabel={Number
        of threads}, ylabel={Total throughput (op/s)}, ymin=0,
      width=\graphWidth]
    
      \addplot[mark=x, cyan, densely dashed, error bars/.cd, y
      dir=both, y explicit] coordinates { (1,504) +- (0,1) (2,419) +-
        (0,11) (4,282) +- (0,15) (8,159) +- (0,4) };

      \addplot[mark=square, red, solid, error bars/.cd, y dir=both, y
      explicit] coordinates { (1,463) +- (0,0) (2,478) +- (0,7)
        (4,458) +- (0,14) (8,506) +- (0,8) };

      \addplot[mark=*, green, densely dotted, error bars/.cd, y
      dir=both, y explicit] coordinates { (1,463) +- (0,3) (2,475) +-
        (0,9) (4,479) +- (0,16) (8,514) +- (0,8) };
      
      \legend{GVSTM, Coarse-grained locking, Medium-grained locking}
    \end{axis}
  \end{tikzpicture}
  \mycaption{Total throughput of a read-write workload with structure
    modifications.}{}
  \label{fig:sm60}
\end{figure}

In my STMBench7 implementation the inclusion of structure
modifications decreases single-threaded throughput by about one order
of magnitude --- note the scale on the vertical axes. This is likely
due to the inefficient implementations of the backend data structures,
which make structure modifications very expensive operations.

As discussed in Section~\ref{sec:impl:operations}, structure
modifications conflict with most other read-write operations. This
means that as more goroutines are used by the GVSTM the rate of
conflicts increases, forcing transactions to abort and waste
computation. This causes the performance of the GVSTM to rapidly
degrade as more goroutines are used, even in a workload with only
$10\%$ of read-write transactions.

The execution of structure modifications requires the acquisition of a
global write-lock in both locking approaches, essentially forcing
sequential execution. This makes it difficult to significantly exceed
single-threaded performance.

\section{Usability}
\label{sec:eval:ease-use}

One of the motivations behind STMs is their usability compared to
lock-based synchronisation. Because a usability survey of a large
number of programmers is beyond the scope of this project, in this
section I will be drawing from my own experience implementing
STMBench7.

\paragraph{Correctness.} The GVSTM makes it much simpler to correctly
synchronise programs, as demonstrated by the operation executors of
STMBench7. Implementing the medium-grained executor caused several
bugs, some of which were caused because Java supports reentrant locks
and Go does not. Appendix~\ref{cha:comp-oper-exec} makes a comparison
between the operation executors.

\paragraph{Code readability.} Reads and writes of versioned boxes are
more verbose than reads and writes of normal variables, which can
decrease the readability of the code. On the other hand, having every
mutable variable wrapped in a versioned box is a useful indicator of
the purpose of a variable, reducing the risk of incorrect use.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Conclusion
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusion}

This dissertation describes three major contributions to the area of
STM implementation in Go:
\begin{itemize}
\item The definition of an STM interface in Go.
\item The implementation of the GVSTM, a multi-version STM.
\item The implementation of STMBench7, a stress test of STM
  implementations.
\end{itemize}

\paragraph{Personal reflection.} This project was largely successful,
and a good first step towards the use of STMs in Go. During the
project I explored convoluted features of the Go programming language
and its memory model, implemented an STM, including its complex
lock-free garbage collection algorithm and gained some experience with
system performance measurement.

I would have liked to spend more time adding features to the GVSTM,
but unfortunately implementing STMBench7 from scratch was very time
consuming. Future projects may benefit from having this work done
ahead of time.

\paragraph{Future work.} In the near future I will aim to turn the
products of this project into open source software, with the goal of
encouraging the use of STMs in Go. Because all the code produced is my
own, I will have to decide on an appropriate licens under which to
release the project. The steps necessary for the project to be
released are the following:
\begin{itemize}
\item Add to the GVSTM implementations of versioned data structures,
  such as lists and sets.
\item Extend the STM interface to also represent transactions that are
  able to explicitly retry and abort, and add this functionality to
  the GVSTM.
\item When the steps above are completed, the STMBench7 implementation
  can be changed to use more sensible backend data structures and
  possibly exploit abort and retry semantics.
\end{itemize}

Future Part II projects may find inspiration from the other extensions
described in Sections~\ref{sec:impl:extensions}
and~\ref{sec:impl:possible-extensions}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\addcontentsline{toc}{chapter}{Bibliography} \bibliography{biblio}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Appendices
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix
\pretocmd{\chapter}{%
  \clearpage
  \pagenumbering{arabic}%
  \renewcommand*{\thepage}{\thechapter\arabic{page}}%
}{}{}

\chapter{Comparison of operation executors}
\label{cha:comp-oper-exec}

Listing~\ref{lst:gvstmOpExec} shows the GVSTM operation executor in
its entirety. The GVSTM executor simply wraps the operation to be
executed in a call to the \goFunc{Atomic} function.

Listing~\ref{lst:cgOpExec} shows the coarse-grained locking
executor. It determines whether to read-acquire or write-acquire the
global read-write mutex based on built-in information about the
operations.

The medium-grained locking executor is about 180 lines of code and
extremely complex --- each operation must acquire some subset of the
locks of the structure in a particular order, and bookkeeping must be
kept to know which locks are held by each executor.

Implementing the locking executors is error prone: mislabelling an
operation as read-only, for example, will violate the invariants of
the structure; acquiring medium-grained locks in a different order may
cause deadlock; adding an operation to the medium-grained
implementation may require a substantial refactor of the executor.

\begin{Listing}[hbtp]
\begin{lstlisting}
type gvstmOperationExecutor struct {
	operation Operation
}

func CreateGVSTMOperationExecutor(operation Operation) OperationExecutor {
	return &gvstmOperationExecutor{operation}
}

func (e *gvstmOperationExecutor) Execute() (result int, err error) {
	gvstm.Atomic(func(tx Transaction) {
		result, err = e.operation.Perform(tx)
	})
	return
}
\end{lstlisting}

  \mycaption{The GVSTM operation executor.}{}
  \label{lst:gvstmOpExec}
\end{Listing}

\begin{Listing}[hbtp]
\begin{lstlisting}
var (
	globalWriteLock = &sync.RWMutex{}
	globalReadLock  = globalWriteLock.RLocker()
)

type cgOperationExecutor struct {
	operation Operation
	lock      sync.Locker
}

func CreateCGOperationExecutor(op Operation) OperationExecutor {
	var lock sync.Locker
	switch op.ID().OpType {
	case OperationRO, TraversalRO, ShortTraversalRO:
		lock = globalReadLock
	default:
		lock = globalWriteLock
	}
	return &cgOperationExecutor{op, lock}
}

func (e *cgOperationExecutor) Execute() (result int, err error) {
	e.lock.Lock()
	defer e.lock.Unlock()
	return e.operation.Perform(nil)
}
\end{lstlisting}

  \mycaption{The coarse-grained operation executor.}{}
  \label{lst:cgOpExec}
\end{Listing}


\chapter{STMBench7 example output}
\label{cha:stmb-example-outp}

Shown below is the output of STMBench7 for one benchmark run. Detailed
statistics of per-operation success rates and times to completion have
been omitted for brevity.

\bigskip

\begin{lstlisting}
-----------------------------------------------
Benchmark parameters
-----------------------------------------------

Number of threads: 4
Length: 2m0s
Read percentage: 90
Synchronisation method: Coarse grained locking
Long traversals enabled: true
Long read-write traversals enabled: true
Structure modification enabled: false

Operation ratios [%]:
            TraversalRW:   0.56
            TraversalRO:   5.00
       ShortTraversalRW:   4.44
       ShortTraversalRO:  40.00
            OperationRW:   5.00
            OperationRO:  45.00
  StructureModification:   0.00

Checking invariants (final data structure):
Invariant check completed successfully!

-----------------------------------------------
Summary results
-----------------------------------------------

TraversalRW:
  successful: 9746
  maxTTC: 13
  failed: 0
  total: 9746
TraversalRO:
  successful: 87552
  maxTTC: 16
  failed: 0
  total: 87552
ShortTraversalRW:
  successful: 19411
  maxTTC: 15
  failed: 58262
  total: 77673
ShortTraversalRO:
  successful: 348620
  maxTTC: 14
  failed: 350100
  total: 698720
OperationRW:
  successful: 85938
  maxTTC: 15
  failed: 1858
  total: 87796
OperationRO:
  successful: 773664
  maxTTC: 14
  failed: 14046
  total: 787710
StructureModification:
  successful: 0
  maxTTC: 0
  failed: 0
  total: 0

Total sample error: 33.33% (0.12% including failed)
Total throughput: 11040.70 op/s (14576.12 op/s including failed)
Elapsed time: 120.00
\end{lstlisting}

\chapter{Benchmarking methodology}
\label{cha:benchm-meth}

All results in this dissertation were produced following the same
methodology:

\begin{itemize}
\item Close all applications and restart my computer, to minimise the
  number of processes running and competing for resources.
\item For each parameter combination (synchronisation mechanism,
  number of goroutines and workload) run the benchmark five times,
  discard the results with maximum and minimum throughput to avoid
  outliers and use the remaining three sets of results.
\item Run the benchmark for two minutes each time, to minimise the
  effects of startup costs. Brief experiments showed that this
  duration was sufficient to produce stable results.
\item Check that the ratio of failed operations does not vary
  significantly between runs, to avoid skewed results.
\end{itemize}
It is worth pointing out that discarding the results with minimum and
maximum throughput reduced the standard deviation of the samples
significantly, making error bars barely visible in most cases. A large
number of samples contained at least one outlier, so I decided to take
this approach in order to treat all samples consistently.

\chapter{Project Proposal}
\label{cha:project-proposal}

The body of my project proposal follows in the next page. The cover
page was removed to avoid personal identifiers.

The rest of this page is intentionally left blank.

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
